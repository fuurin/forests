{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference  \n",
    "https://lp-tech.net/articles/hzfn7\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パッチ分割用ソースコードはimagePatcherSemSeg.py\n",
    "\n",
    "``` \n",
    "$ python imagePatcherSemSeg.py ./datasets/wM1 500 ./results/ wM\n",
    "```\n",
    "\n",
    "のようにして実行するとモザイク画像をパッチに分割し，かつセグメンテーションもしてくれる．  \n",
    "このデータセットを使って学習をするのかと？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch による画像セグメンテーション  \n",
    "データセットは https://www.kaggle.com/c/carvana-image-masking-challenge/data  \n",
    "kaggleアカウント作って電話番号とかでVerifyして色々めんどいけどなんとか．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PytorchのインストールはURLから．  \n",
    "https://pytorch.org/ を参照  \n",
    "\n",
    "Windows  \n",
    "```\n",
    "$ pip install https://download.pytorch.org/whl/cpu/torch-1.1.0-cp37-cp37m-win_amd64.whl\n",
    "$ pip install https://download.pytorch.org/whl/cpu/torchvision-0.3.0-cp37-cp37m-win_amd64.whl\n",
    "```\n",
    "\n",
    "Mac  \n",
    "```\n",
    "$ pip install torch torchvision\n",
    "$ brew install libomp\n",
    "```\n",
    "\n",
    "https://github.com/pytorch/pytorch/issues/20030"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PydensecrfはpipでインストールしようとするとEigenとかいうC++のライブラリでつっかかることがある．その場合は，  \n",
    "- venvを使っているならアクティベート\n",
    "- https://github.com/lucasb-eyer/pydensecrf をクローン  \n",
    "- http://eigen.tuxfamily.org/index.php?title=Main_Page から最新のEigenライブラリをダウンロードし，解凍\n",
    "- 解凍した中に入っているEigenディレクトリを，pydensecrf/pydensecrf/densecrf/include/Eigenに上書き\n",
    "- pydensecrfディレクトリの直下で，python setup.py install\n",
    "- これにてインストール成功  \n",
    "  \n",
    "参考: https://github.com/lucasb-eyer/pydensecrf/issues/69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, numpy as np\n",
    "from optparse import OptionParser\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Function, Variable\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラム内で使用する変数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_IMG = 'datasets/carvana/train/'\n",
    "DIR_MASK = 'datasets/carvana/train_masks/'\n",
    "DIR_IMG_TEST = 'datasets/carvana/test/'\n",
    "DIR_CHECKPOINT = 'results/carvana/checkpoint/'\n",
    "VAL_PERCENT = 0.05 # テスト用データの割合\n",
    "SCALE = 0.5\n",
    "N = 2\n",
    "BATCH_SIZE = 2\n",
    "EPOCH = 5\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cropped(ids, dir, suffix):\n",
    "    for id, pos in ids:\n",
    "        img = Image.open(dir + id + suffix)\n",
    "        \n",
    "        w = img.size[0]\n",
    "        h = img.size[1]\n",
    "        newW = int(w * SCALE)\n",
    "        newH = int(h * SCALE)\n",
    "        \n",
    "        img = img.resize((newW, newH))\n",
    "        img = img.crop((0, 0, newW, newH)) # 左上1/4のみを切り取る意味は実験を早めるため？\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        \n",
    "        h = img.shape[0]\n",
    "        if pos == 0:\n",
    "            img = img[:, :h]\n",
    "        else:\n",
    "            img = img[:, -h:]\n",
    "        \n",
    "        yield img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像とマスク画像の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_mask(ids):\n",
    "    img = to_cropped(ids, DIR_IMG, '.jpg')\n",
    "    img = map(lambda x: np.transpose(x, axes=[2, 0, 1]), img)\n",
    "    img = map(lambda x: x / 255, img)\n",
    "    \n",
    "    mask = to_cropped(ids, DIR_MASK, '_mask.gif')\n",
    "    \n",
    "    return zip(img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチ化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, batch_size):\n",
    "    b = []\n",
    "    for i, t in enumerate(iterable):\n",
    "        b.append(t)\n",
    "        if (i + 1) % batch_size == 0:\n",
    "            yield b # batch_sizeの数だけまとめてyield\n",
    "            b = []\n",
    "    \n",
    "    if len(b) > 0:\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拡張子を取り払ったID部分の配列\n",
    "ids_all = [f[:-4] for f in os.listdir(DIR_IMG)]\n",
    "\n",
    "# 全てのIDを2つにコピー\n",
    "ids_all = [(idx, i) for i in range(N) for idx in ids_all]\n",
    "\n",
    "random.shuffle(ids_all)\n",
    "\n",
    "# 全訓練データ数？\n",
    "n = int(len(ids_all) * VAL_PERCENT)\n",
    "\n",
    "# 訓練データとテストデータを分けている？\n",
    "ids = {'train': ids_all[:-n], 'val': ids_all[-n:]}\n",
    "\n",
    "len_train = len(ids['train'])\n",
    "len_val = len(ids['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Netの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "        \n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x1.size()[2] - x2.size()[2]\n",
    "        diffY = x1.size()[3] - x2.size()[3]\n",
    "        x2 = F.pad(x2, (diffX // 2, int(diffX / 2), \n",
    "                        diffY // 2, int(diffY / 2)))\n",
    "        x = torch.cat([x2, x1], dim=1) # catenate? でマージ\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up(1024, 256)\n",
    "        self.up2 = up(512, 128) # Uの左側からやってくるデータとマージを行うので入力2倍\n",
    "        self.up3 = up(256, 64)\n",
    "        self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice係数を算出するクラス  \n",
    "https://mieruca-ai.com/ai/jaccard_dice_simpson/  \n",
    "集合同士の類似度の一種  \n",
    "$$ DSC(A, B) = \\frac{2|A \\cap B|}{|A| + |B|} $$\n",
    "片方の要素数がもう片方より多い時には無駄に結果が小さくなってしまうJaccard係数とは違い，2つの集合の平均要素数を計算することで，共通要素数を重視した類似度計算を行う係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for indivisual examples\"\"\"\n",
    "    def forward(self, inpt, target):\n",
    "        self.save_for_backward(input, target)\n",
    "        eps = 0.0001\n",
    "        self.inter = torch.dot(inpt.view(-1), target.view(-1))\n",
    "        self.union = torch.sum(inpt) + torch.sum(target) + eps\n",
    "        \n",
    "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
    "        return t\n",
    "    \n",
    "    # 単一の出力しか持たないため，勾配も一つだけ\n",
    "    def backward(self, grad_output):\n",
    "        inpt, target = self.saved_variables\n",
    "        grad_input = grad_target = None\n",
    "        \n",
    "        if self.needs_input_grad[0]:\n",
    "            grad_input = grad_output * 2 * (target * self.union + self.inter) \\\n",
    "                            / self.union * self.union\n",
    "        if self.needs_input_grad[1]:\n",
    "            grad_target = None\n",
    "        \n",
    "        return grad_input, grad_target\n",
    "\n",
    "def dice_coeff(inpt, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    if inpt.is_cuda:\n",
    "        s = torch.FloatTensor(1).cuda().zero_()\n",
    "    else:\n",
    "        s = torch.FloatTensor(1).zero_()\n",
    "    \n",
    "    for i, c in enumerate(zip(inpt, target)):\n",
    "        s = s + DiceCoeff().forward(c[0], c[1])\n",
    "    \n",
    "    return s / (i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-86cf410fec78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmask_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mmask_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mmask_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmask_prob_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programming\\projects\\forests\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-a9cc42959f64>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mup4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programming\\projects\\forests\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programming\\projects\\forests\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net = UNet(n_channels=3, n_classes=1).cuda()\n",
    "else:\n",
    "    net = UNet(n_channels=3, n_classes=1).cpu()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train = get_img_mask(ids['train'])\n",
    "    val = get_img_mask(ids['val'])\n",
    "    \n",
    "    # train section\n",
    "    epoch_loss = 0\n",
    "    for i, b in enumerate(batch(train, BATCH_SIZE)):\n",
    "        img = np.array([i[0] for i in b]).astype(np.float32)\n",
    "        mask = np.array([i[1] for i in b])\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            img = torch.from_numpy(img).cuda()\n",
    "            mask = torch.from_numpy(mask).cuda()\n",
    "        else:\n",
    "            img = torch.from_numpy(img).cpu()\n",
    "            mask = torch.from_numpy(mask).cpu()\n",
    "        \n",
    "        mask_flat = mask.view(-1)\n",
    "        \n",
    "        mask_pred = net(img) # prediction\n",
    "        mask_prob = F.sigmoid(mask_pred) # probability\n",
    "        mask_prob_flat = mask_prob.view(-1)\n",
    "        \n",
    "        loss = criterion(mask_prob_flat, mask_flat)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'{i} / {int(len_train/BATCH_SIZE)} ---- loss: {loss.item()}')\n",
    "    \n",
    "    print(f'Epoch finished ! Loss: {epoch_loss / len_train}')\n",
    "    \n",
    "    # ---- val section\n",
    "    val_dice = 0\n",
    "    for j, b in enumerate(val):\n",
    "        if torch.cuda.is_available():\n",
    "            img = torch.from_numpy(b[0]).unsqueeze(0).cuda()\n",
    "            mask = torch.from_numpy(b[1]).unsqueeze(0).cuda()\n",
    "        else:\n",
    "            img = torch.from_numpy(b[0]).unsqueeze(0).cpu()\n",
    "            mask = torch.from_numpy(b[1]).unsqueeze(0).cpu()\n",
    "        \n",
    "        mask_pred = net(img)[0]\n",
    "        mask_prob = F.sigmoid(mask_pred)\n",
    "        mask_bin = (mask_prob > 0.5).float()\n",
    "        val_dice += dice_coeff(mask_bin, mask).item()\n",
    "        \n",
    "        if j % 10 == 0:\n",
    "            print(f\"val: {j}/{len_val}\")\n",
    "    \n",
    "    torch.save(net.state_dict(), f\"{DIR_CHECKPOINT}CP{epoch+1}.pth\")\n",
    "    print(f\"Checkpoint {epoch+1} saved !\")\n",
    "    print(f\"Validation Dice Coeff: {val_dice / len_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータによる評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_img_test = os.listdir(DIR_IMG_TEST)\n",
    "random.shuffle(file_img_test)\n",
    "\n",
    "for i, file in enumerate(file_img_test):\n",
    "    img_original = Image.open(DIR_IMG_TEST+file)\n",
    "    img = img_original\n",
    "    \n",
    "    w = img.size[0]\n",
    "    h = img.size[1]\n",
    "    \n",
    "    newW = int(w * SCALE)\n",
    "    newH = int(h * SCALE)\n",
    "    \n",
    "    img = img.resize((newW, newH))\n",
    "    img = img.crop((0, 0, newW, newH))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = img / 255\n",
    "    \n",
    "    img_left = img[:, :newH]\n",
    "    img_right = img[;, -newH:]\n",
    "    \n",
    "    img_left = np.transpose(img_left, axes=[2, 0, 1])\n",
    "    img_right = np.transpose(img_right, axes=[2, 0, 1])\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        img_left = torch.from_numpy(img_left).unsqueeze(0).cuda()\n",
    "        img_right = torch.from_numpy(img_right).unsqueeze(0).cuda()\n",
    "    else:\n",
    "        img_left = torch.from_numpy(img_left).unsqueeze(0).cpu()\n",
    "        img_right = torch.from_numpy(img_right).unsqueeze(0).cpu()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mask_left = net(img_left)\n",
    "        mask_right = net(img_right)\n",
    "\n",
    "        mask_prob_left = F.sigmoid(mask_left).squeeze(0)\n",
    "        mask_prob_right = F.sigmoid(mask_right).squeeze(0)\n",
    "        \n",
    "        tf = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(h),\n",
    "                transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        mask_prob_left = tf(mask_prob_left.cpu())\n",
    "        mask_prob_right = tf(mask_prob_right.cpu())\n",
    "        \n",
    "        mask_prob_left_np = mask_prob_left.squeeze().cpu().numpy()\n",
    "        mask_prob_right_np = mask_prob_right.squeeze().cpu().numpy()\n",
    "        \n",
    "        mask_prob_np = np.zeros((h, w), np.float32)\n",
    "        mask_prob_np[:, :w//2+1] = mask_prob_left_np[:, :w//2+1]\n",
    "        mask_prob_np[:, w//2+1:] = mask_prob_right_np[:, -(w//2-1):]\n",
    "            \n",
    "        \n",
    "        h = mask_prob_np.shape[0]\n",
    "        w = mask_prob_np.shape[1]\n",
    "\n",
    "        mask_prob_np = np.expand_dims(mask_prob_np, 0)\n",
    "        mask_prob_np = np.append(1 - mask_prob_np, mask_prob_np, axis=0)\n",
    "\n",
    "        d = dcrf.DenseCRF2D(w, h, 2)\n",
    "        U = -np.log(mask_prob_np)\n",
    "        U = U.reshape((2, -1))\n",
    "        U = np.ascontiguousarray(U)\n",
    "        img = np.ascontiguousarray(np.array(img_original).astype(np.uint8))\n",
    "\n",
    "        d.setUnaryEnergy(U)\n",
    "\n",
    "        d.addPairwiseGaussian(sxy=20, compat=3)\n",
    "        d.addPairwiseBilateral(sxy=30, srgb=20, rgbim=img, compat=10)\n",
    "\n",
    "        mask = d.inference(5)\n",
    "        mask = np.argmax(np.array(mask), axis=0).reshape((h, w))        \n",
    "        mask = mask_prob_np > args['threshold']\n",
    "        mask = Image.fromarray((mask[0] * 255).astype(np.uint8))\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(27, 7))\n",
    "\n",
    "        ax1 = fig.add_subplot(131)    \n",
    "        ax1.imshow(img_original)\n",
    "        ax1.set_title('input', fontsize=28)\n",
    "\n",
    "        ax2 = fig.add_subplot(132)\n",
    "        ax2.imshow(mask)\n",
    "        ax2.set_title('output', fontsize=28)\n",
    "\n",
    "        ax3 = fig.add_subplot(133)\n",
    "        ax3.imshow(img_original)\n",
    "        ax3.imshow(mask, alpha=0.8)\n",
    "        ax3.set_title('input and output', fontsize=28)\n",
    "        \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
